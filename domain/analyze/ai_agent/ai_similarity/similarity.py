"""
ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹œìŠ¤í…œ (OpenCLIP ViT-g-14 ë²„ì „)
================================================

ì…ë ¥ ìŠ¤í™:
---------
1. INPUT_DIR: "test" í´ë”ì— ê²€ìƒ‰í•  ì´ë¯¸ì§€ íŒŒì¼ë“¤ (.jpg, .jpeg, .png, .webp, .bmp)
2. USED_DIR: "train" í´ë”ì— ë¹„êµ ëŒ€ìƒ ì´ë¯¸ì§€ë“¤
3. FEATURES_NPY: "embeddings/train_features_vit_g_14.npy" - train í´ë” ì´ë¯¸ì§€ë“¤ì˜ OpenCLIP ì„ë² ë”© ë²¡í„°
4. PATHS_NPY: "embeddings/train_paths_vit_g_14.npy" - train í´ë” ì´ë¯¸ì§€ë“¤ì˜ íŒŒì¼ ê²½ë¡œ
5. PRODUCTS_CSV: "records/carbot_data_final.csv" - ìƒí’ˆ ì •ë³´ (ìƒí’ˆëª…, ì •ê°€, ì¤‘ê³ ê°€, ë§í¬)
6. MODEL_NAME: 'open_clip/ViT-g-14' - OpenCLIP ëª¨ë¸ëª…
7. TOPK: 5 - ê²€ìƒ‰ ê²°ê³¼ ìƒìœ„ ê°œìˆ˜

ì¶œë ¥ ìŠ¤í™:
---------
1. ì‹œê°í™”: ì¿¼ë¦¬ ì´ë¯¸ì§€ + top k ìœ ì‚¬ ì´ë¯¸ì§€ë“¤ì„ 1í–‰ìœ¼ë¡œ í‘œì‹œ
2. í…ìŠ¤íŠ¸: ê° ì´ë¯¸ì§€ì˜ ìˆœìœ„, íŒŒì¼ëª…, í´ë”ëª…, ìœ ì‚¬ë„, ì •ê°€, ì¤‘ê³ ê°€, ë§í¬
3. ë°˜í™˜ê°’: ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ (return_results=Trueì¼ ë•Œ)

ì‚¬ìš©ë²•:
------
search_by_image_name("ì´ë¯¸ì§€íŒŒì¼ëª….jpg")  # ì‹œê°í™” í¬í•¨
get_search_results_only("ì´ë¯¸ì§€íŒŒì¼ëª….jpg")  # ê²°ê³¼ë§Œ ë°˜í™˜
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'  # OpenMP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶©ëŒ ë°©ì§€
import gc
import warnings
from typing import List, Dict, Tuple, Optional, Union, Any, Callable
warnings.filterwarnings('ignore')
import time

from PIL import Image
import torch
import open_clip

# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows í™˜ê²½)
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# ==================== ì‹œìŠ¤í…œ ì„¤ì • ====================
INPUT_DIR: str = "test"                     # ë°±ì—”ë“œì—ì„œ ë„˜ê²¨ë°›ì€ ìœ ì €ê°€ ì…ë ¥í•œ ì´ë¯¸ì§€ í´ë” ë˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ì¼
USED_DIR: str = "train"                     # ë¹„êµ ëŒ€ìƒ ì´ë¯¸ì§€ë“¤ì´ ìˆëŠ” í´ë” (train í´ë”)

FEATURES_NPY: str = "embeddings/train_features_vit_g_14.npy"  # train í´ë” ì´ë¯¸ì§€ë“¤ì˜ ì„ë² ë”© ë²¡í„°
PATHS_NPY: str = "embeddings/train_paths_vit_g_14.npy"        # train í´ë” ì´ë¯¸ì§€ë“¤ì˜ íŒŒì¼ ê²½ë¡œ
MODEL_NAME: str = 'ViT-g-14'     # OpenCLIP ëª¨ë¸ëª… (ì •í™•í•œ ëª¨ë¸ëª…ìœ¼ë¡œ ìˆ˜ì • í•„ìš”)

PRODUCTS_CSV: str = "records/carbot_data_final.csv"     # ìƒí’ˆ ì •ë³´ CSV íŒŒì¼

TOPK: int = 1                              # ê²€ìƒ‰ ê²°ê³¼ ìƒìœ„ ê°œìˆ˜

def load_model(model_name: str, device: torch.device) -> Tuple[open_clip.CLIP, Callable]:
    """
    OpenCLIP ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    FP16 (Half Precision)ì„ ì ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê³  ì†ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
    """
    print(f"ğŸ” ëª¨ë¸ ë¡œë“œ ì‹œì‘: {model_name}")
    model, _, preprocess = open_clip.create_model_and_transforms(
        model_name,
        pretrained="laion2b_s34b_b88k",
        device=device
    )
    model.eval()
    
    # FP16ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ ë° ì†ë„ í–¥ìƒ
    if device.type == 'cuda':
        model.half()
        # print("âœ… FP16 (Half Precision) ì ìš© ì™„ë£Œ - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 50% ê°ì†Œ, ì†ë„ í–¥ìƒ")
    
    return model, preprocess

def embed_image(model: open_clip.CLIP, transforms_obj: Callable, img_path: str, device: torch.device) -> np.ndarray:
    """
    ì´ë¯¸ì§€ì˜ OpenCLIP ì„ë² ë”© ë²¡í„°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    FP16 ìµœì í™”ê°€ ì ìš©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    """
    from PIL import Image
    import torch
    import numpy as np

    image = Image.open(img_path).convert("RGB")
    with torch.no_grad():
        # FP16ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ
        inputs = transforms_obj(image).unsqueeze(0)
        if device.type == 'cuda':
            inputs = inputs.half()
        inputs = inputs.to(device)
        
        feat = model.encode_image(inputs)
        feat = feat / feat.norm(p=2, dim=-1, keepdim=True)
    
    # detach()ë¥¼ ì¶”ê°€í•˜ì—¬ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ê·¸ë˜í”„ì—ì„œ ë¶„ë¦¬, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ
    return feat.detach().cpu().numpy().astype("float32").flatten()

def list_input_images() -> List[str]:
    """
    input í´ë”ì˜ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    ì…ë ¥: ì—†ìŒ
    
    ì¶œë ¥:
        List[str]: ì§€ì›ë˜ëŠ” ì´ë¯¸ì§€ í™•ì¥ìë¥¼ ê°€ì§„ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸
    """
    if not os.path.isdir(INPUT_DIR):
        print(f"âŒ {INPUT_DIR} í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    allowed_exts: set = {".jpg", ".jpeg", ".png", ".webp", ".bmp"}
    images: List[str] = []
    
    for f in os.listdir(INPUT_DIR):
        if os.path.splitext(f)[1].lower() in allowed_exts:
            images.append(f)
    
    images.sort()
    return images

def load_products_info() -> Dict[str, Dict[str, Any]]:
    """
    carbot_data_final.csv íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ìƒí’ˆ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    ì…ë ¥: ì—†ìŒ
    
    ì¶œë ¥:
        Dict[str, Dict[str, Any]]: {ìƒí’ˆëª…: {retail_price, used_price_avg, retail_link}} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    try:
        if os.path.isfile(PRODUCTS_CSV):
            df: pd.DataFrame = pd.read_csv(PRODUCTS_CSV)
            products_dict: Dict[str, Dict[str, Any]] = {}
            
            for _, row in df.iterrows():
                product_name: str = str(row['product_name']).strip()
                retail_price: Any = row['retail_price']
                used_price_avg: Any = row['used_price_avg']
                retail_link: str = str(row['retail_link']).strip()
                
                products_dict[product_name] = {
                    'retail_price': retail_price,
                    'used_price_avg': used_price_avg,
                    'retail_link': retail_link
                }
            
            print(f"âœ… {len(products_dict)}ê°œì˜ ìƒí’ˆ ì •ë³´ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            return products_dict
        else:
            print(f"âš ï¸  {PRODUCTS_CSV} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {}
    except Exception as e:
        print(f"âŒ ìƒí’ˆ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

# def get_product_info_from_path(image_path: str, products_dict: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
#     """
#     ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ í´ë”ëª…ì„ ì¶”ì¶œí•˜ì—¬ í•´ë‹¹ ìƒí’ˆì˜ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
#     ì…ë ¥:
#         image_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
#         products_dict (Dict[str, Dict[str, Any]]): ìƒí’ˆ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    
#     ì¶œë ¥:
#         Dict[str, Any]: ìƒí’ˆ ì •ë³´ ë˜ëŠ” ê¸°ë³¸ê°’
#     """
#     # ê²½ë¡œì—ì„œ í´ë”ëª… ì¶”ì¶œ (ë§ˆì§€ë§‰ í´ë”ëª…ì´ ìƒí’ˆëª…)
#     path_parts = image_path.replace('\\', '/').split('/')
#     folder_name = path_parts[-2] if len(path_parts) > 1 else ""
    
#     # í´ë”ëª…ì—ì„œ ìƒí’ˆëª… ì¶”ì¶œ (í—¬ë¡œì¹´ë´‡_ ì ‘ë‘ì‚¬ ì œê±°)
#     if folder_name.startswith("í—¬ë¡œì¹´ë´‡_"):
#         product_name = folder_name[6:]  # "í—¬ë¡œì¹´ë´‡_" ì œê±°
#     else:
#         product_name = folder_name
    
#     # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
#     if product_name in products_dict:
#         return products_dict[product_name]
    
#     # ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (í´ë”ëª…ì´ ìƒí’ˆëª…ì˜ ì¼ë¶€ì¸ ê²½ìš°)
#     for key, info in products_dict.items():
#         if product_name in key or key in product_name:
#             return info
    
#     # ë§¤ì¹­ë˜ì§€ ì•ŠëŠ” ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
#     return {
#         'retail_price': 'ê°€ê²© ì •ë³´ ì—†ìŒ',
#         'used_price_avg': 'ì¤‘ê³ ê°€ ì •ë³´ ì—†ìŒ',
#         'retail_link': 'ë§í¬ ì—†ìŒ'
#     }

def get_product_info_from_path(image_path: str, products_dict: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
    # ê²½ë¡œì—ì„œ í´ë”ëª… ì¶”ì¶œ
    path_parts = image_path.replace('\\', '/').split('/')
    folder_name = path_parts[-2] if len(path_parts) > 1 else ""
    
    # í´ë”ëª…ì—ì„œ ìƒí’ˆëª… ì¶”ì¶œ (í—¬ë¡œì¹´ë´‡_ ì ‘ë‘ì‚¬ ì œê±°)
    if folder_name.startswith("í—¬ë¡œì¹´ë´‡_"):
        product_name = folder_name[6:]  # "í—¬ë¡œì¹´ë´‡_" ì œê±°
    else:
        product_name = folder_name
    
    # ì–¸ë”ìŠ¤ì½”ì–´ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ CSV í‚¤ì™€ ë§¤ì¹­
    product_name_clean = product_name.replace('_', ' ')
    
    # 1ë‹¨ê³„: ì •í™•í•œ ë§¤ì¹­ ì‹œë„ (ì–¸ë”ìŠ¤ì½”ì–´ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜ í›„)
    exact_match_key = f"í—¬ë¡œì¹´ë´‡ {product_name_clean}"
    if exact_match_key in products_dict:
        return products_dict[exact_match_key]
    
    # 2ë‹¨ê³„: ì›ë³¸ í´ë”ëª…ìœ¼ë¡œë„ ì‹œë„
    if folder_name in products_dict:
        return products_dict[folder_name]
    
    # 3ë‹¨ê³„: ë¶€ë¶„ ë§¤ì¹­ ì‹œë„
    best_match = None
    best_score = 0
    
    for key, info in products_dict.items():
        if product_name_clean in key or product_name in key:
            score = len(product_name_clean) / len(key)
            if score > best_score:
                best_score = score
                best_match = (key, info)
    
    if best_match:
        return best_match[1]
    
    # 4ë‹¨ê³„: ë§¤ì¹­ë˜ì§€ ì•ŠëŠ” ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
    return {
        'retail_price': 'ê°€ê²© ì •ë³´ ì—†ìŒ',
        'used_price_avg': 'ì¤‘ê³ ê°€ ì •ë³´ ì—†ìŒ',
        'retail_link': 'ë§í¬ ì—†ìŒ'
    }

def search_similar_images(query_image_path: str, features: np.ndarray, paths: np.ndarray, 
                         model: open_clip.CLIP, transforms_obj: Callable, device: torch.device, 
                         top_k: int = 5) -> Tuple[List[Dict[str, Union[int, float, str]]], float, float]:
    """
    ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    ì…ë ¥:
        query_image_path (str): ê²€ìƒ‰í•  ì´ë¯¸ì§€ ê²½ë¡œ
        features (np.ndarray): ëª¨ë“  ì´ë¯¸ì§€ì˜ ì„ë² ë”© ë²¡í„° (N x ì°¨ì›)
        paths (np.ndarray): ëª¨ë“  ì´ë¯¸ì§€ì˜ íŒŒì¼ ê²½ë¡œ
        model (open_clip.CLIP): OpenCLIP ëª¨ë¸ ê°ì²´
        transforms_obj (open_clip.transform.Transforms): OpenCLIP ì „ì²˜ë¦¬ ë³€í™˜
        device (torch.device): GPU ë˜ëŠ” CPU ë””ë°”ì´ìŠ¤
        top_k (int): ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ê°œìˆ˜
    
    ì¶œë ¥:
        Tuple[List[Dict[str, Union[int, float, str]]], float, float]: 
            (ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸, ì„ë² ë”© ìƒì„± ì‹œê°„, ìœ ì‚¬ë„ ê³„ì‚° ì‹œê°„)
            [{'rank': 1, 'path': 'ê²½ë¡œ', 'similarity': 0.8, 'filename': 'íŒŒì¼ëª…'}, ...]
    """
    try:
        # ì¿¼ë¦¬ ì´ë¯¸ì§€ ì„ë² ë”© ê³„ì‚° ì‹œê°„ ì¸¡ì •
        embedding_start = time.time()
        q: np.ndarray = embed_image(model, transforms_obj, query_image_path, device)
        embedding_time = time.time() - embedding_start
        
        # ì°¨ì› í™•ì¸ ë° ì¡°ì •
        query_dim = q.shape[0]
        features_dim = features.shape[1]
        
        # print(f"ğŸ” ì°¨ì› ì •ë³´: ì¿¼ë¦¬ ì´ë¯¸ì§€ {query_dim}ì°¨ì›, ì €ì¥ëœ ì„ë² ë”© {features_dim}ì°¨ì›")
        
        if query_dim != features_dim:
            print(f"âš ï¸  ì°¨ì› ë¶ˆì¼ì¹˜ ê°ì§€! ì¿¼ë¦¬: {query_dim}ì°¨ì›, ì €ì¥ëœ ì„ë² ë”©: {features_dim}ì°¨ì›")
            print("   ì €ì¥ëœ ì„ë² ë”©ê³¼ ë™ì¼í•œ ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.")
            return [], embedding_time, 0.0
        
        # ìœ ì‚¬ë„ ê³„ì‚° ì‹œê°„ ì¸¡ì •
        similarity_start = time.time()
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°ì„ ìœ„í•œ ì •ê·œí™”
        q = q / (np.linalg.norm(q) + 1e-9)
        features_norm: np.ndarray = features / (np.linalg.norm(features, axis=1, keepdims=True) + 1e-9)
        
        # ìœ ì‚¬ë„ ê³„ì‚° (ì •ê·œí™”ëœ ë²¡í„°ì˜ ë‚´ì  = ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
        sims: np.ndarray = features_norm @ q
        # sims = np.dot(features_norm, q) 
        top_idx: np.ndarray = np.argsort(sims)[::-1][:top_k]  # ìœ ì‚¬ë„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        
        # ê²°ê³¼ ìƒì„±
        results: List[Dict[str, Union[int, float, str]]] = []
        for rank, i in enumerate(top_idx, start=1):
            results.append({
                'rank': rank,
                'path': str(paths[i]),
                'similarity': float(sims[i]),
                'filename': os.path.basename(str(paths[i]))
            })
        
        similarity_time = time.time() - similarity_start
        
        return results, embedding_time, similarity_time
        
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return [], 0.0, 0.0

def visualize_search_results_with_query(query_image_path: str, results: List[Dict[str, Union[int, float, str]]], 
                                      products_dict: Dict[str, Any], figsize: Tuple[int, int] = (20, 8)) -> None:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤. (ì¿¼ë¦¬ ì´ë¯¸ì§€ + ê²°ê³¼ ì´ë¯¸ì§€ë“¤)
    
    ì…ë ¥:
        query_image_path (str): ì¿¼ë¦¬ ì´ë¯¸ì§€ ê²½ë¡œ
        results (List[Dict[str, Union[int, float, str]]]): ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        products_dict (Dict[str, Any]): ìƒí’ˆ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        figsize (Tuple[int, int]): ê·¸ë˜í”„ í¬ê¸° (ê°€ë¡œ, ì„¸ë¡œ)
    
    ì¶œë ¥: ì—†ìŒ (matplotlib ê·¸ë˜í”„ í‘œì‹œ)
    """
    if not results:
        print("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì¿¼ë¦¬ ì´ë¯¸ì§€ ë¡œë“œ
    try:
        query_img: Image.Image = Image.open(query_image_path).convert('RGB')
        print(f"âœ… ì¿¼ë¦¬ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {os.path.basename(query_image_path)}")
    except Exception as e:
        print(f"âŒ ì¿¼ë¦¬ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # ê²°ê³¼ ì´ë¯¸ì§€ë“¤ ë¡œë“œ
    result_images: List[Image.Image] = []
    for result in results:
        try:
            img: Image.Image = Image.open(str(result['path'])).convert('RGB')
            result_images.append(img)
        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {result['path']} - {e}")
            # ë¹ˆ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´
            result_images.append(Image.new('RGB', (224, 224), color='gray'))
    
    # 1í–‰ìœ¼ë¡œ ì‹œê°í™” (ì¿¼ë¦¬ ì´ë¯¸ì§€ + top k ê²°ê³¼)
    total_images: int = 1 + len(results)  # ì¿¼ë¦¬ ì´ë¯¸ì§€ 1ê°œ + ê²°ê³¼ ì´ë¯¸ì§€ë“¤
    fig, axes = plt.subplots(1, total_images, figsize=figsize)
    fig.suptitle(f'Similarity results: {os.path.basename(query_image_path)}', fontsize=20, fontweight='bold')
    
    # 1ë²ˆì§¸ ìœ„ì¹˜: ì¿¼ë¦¬ ì´ë¯¸ì§€
    ax = axes[0] if total_images > 1 else axes
    ax.imshow(query_img)
    
    # ì¿¼ë¦¬ ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ í´ë”ëª… ì¶”ì¶œ
    query_path_parts = query_image_path.replace('\\', '/').split('/')
    query_folder_name = query_path_parts[-2] if len(query_path_parts) > 1 else "ì•Œ ìˆ˜ ì—†ìŒ"
    
    ax.set_title(f'Input image\n{query_folder_name}', fontsize=14, fontweight='bold', color='blue')
    ax.axis('off')
    
    # 2ë²ˆì§¸ ìœ„ì¹˜ë¶€í„°: ê²°ê³¼ ì´ë¯¸ì§€ë“¤
    for i, (result, img) in enumerate(zip(results, result_images)):
        ax = axes[i + 1] if total_images > 1 else axes
        
        ax.imshow(img)
        
        # ê°€ê²© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        price_info: Dict[str, Any] = get_product_info_from_path(str(result['path']), products_dict)
        
        # ì œëª©ì— ìˆœìœ„, íŒŒì¼ëª…, ìœ ì‚¬ë„, ê°€ê²© í‘œì‹œ
        retail_price = price_info['retail_price'] if price_info['retail_price'] != 'ê°€ê²© ì •ë³´ ì—†ìŒ' else 'N/A'
        used_price = price_info['used_price_avg'] if price_info['used_price_avg'] != 'ì¤‘ê³ ê°€ ì •ë³´ ì—†ìŒ' else 'N/A'
        
        title: str = f"#{result['rank']}\n{result['filename']}\nìœ ì‚¬ë„: {result['similarity']:.4f}\nì •ê°€: {retail_price}\nì¤‘ê³ ê°€: {used_price}"
        ax.set_title(title, fontsize=10, fontweight='bold')
        ax.axis('off')
        
        # ìœ ì‚¬ë„ì— ë”°ë¥¸ í…Œë‘ë¦¬ ìƒ‰ìƒ ì„¤ì •
        if float(result['similarity']) > 0.8:
            color: str = 'green'      # ë†’ì€ ìœ ì‚¬ë„
        elif float(result['similarity']) > 0.6:
            color: str = 'orange'     # ì¤‘ê°„ ìœ ì‚¬ë„
        else:
            color: str = 'red'        # ë‚®ì€ ìœ ì‚¬ë„
        
        # í…Œë‘ë¦¬ ì¶”ê°€
        rect = patches.Rectangle((0, 0), img.width-1, img.height-1, 
                                linewidth=3, edgecolor=color, facecolor='none')
        ax.add_patch(rect)
    
    plt.tight_layout()
    plt.show()
    
    # í…ìŠ¤íŠ¸ ê²°ê³¼ë„ ì¶œë ¥
    print(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ (ìƒìœ„ {len(results)}ê°œ)")
    print("=" * 100)
    for result in results:
        price_info: Dict[str, Any] = get_product_info_from_path(str(result['path']), products_dict)
        
        # ê²½ë¡œì—ì„œ í´ë”ëª…ê³¼ íŒŒì¼ëª… ì¶”ì¶œ
        path_parts = str(result['path']).replace('\\', '/').split('/')
        folder_name = path_parts[-2] if len(path_parts) > 1 else "ì•Œ ìˆ˜ ì—†ìŒ"
        filename = result['filename']
        
        # ê°€ê²© ì •ë³´ í¬ë§·íŒ…
        retail_price = price_info['retail_price'] if price_info['retail_price'] != 'ê°€ê²© ì •ë³´ ì—†ìŒ' else 'N/A'
        used_price = price_info['used_price_avg'] if price_info['used_price_avg'] != 'ì¤‘ê³ ê°€ ì •ë³´ ì—†ìŒ' else 'N/A'
        
        print(f"{result['rank']:2d}. {filename}")
        print(f"    ğŸ“ í´ë”: {folder_name}")
        print(f"    ğŸ’° ì •ê°€: {retail_price}")
        print(f"    ğŸ’° ì¤‘ê³ ê°€: {used_price}")
        print(f"    ğŸ“ ìœ ì‚¬ë„: {result['similarity']:.4f}")
        print(f"    ğŸ”— ë§í¬: {price_info['retail_link']}")
        print("-" * 80)

def search_by_image_name(image_name: str, return_results: bool = False) -> Optional[Union[List[Dict[str, Union[int, float, str]]], Dict[str, Union[str, int]]]]:
    """
    ì´ë¯¸ì§€ëª…ì„ ì…ë ¥ë°›ì•„ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
    
    ì…ë ¥:
        image_name (str): ê²€ìƒ‰í•  ì´ë¯¸ì§€ íŒŒì¼ëª…
        return_results (bool): Trueë©´ top1 ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ë°˜í™˜, Falseë©´ ì‹œê°í™”ë§Œ
    
    ì¶œë ¥:
        Optional[Union[List[Dict[str, Union[int, float, str]]], Dict[str, Union[str, int]]]]: 
            return_results=Trueì¼ ë•Œ top1 ê²°ê³¼ JSON, Falseì¼ ë•Œ None
    """
    
    print(f"ğŸ” ê²€ìƒ‰ ì‹œì‘: {image_name}")
    
    # ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ í™•ì¸
    query_image_path: str = os.path.join(INPUT_DIR, image_name)
    if not os.path.isfile(query_image_path):
        print(f"âŒ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {query_image_path}")
        print(f"\nğŸ“ {INPUT_DIR} í´ë”ì˜ ì‚¬ìš© ê°€ëŠ¥í•œ ì´ë¯¸ì§€ë“¤:")
        input_images: List[str] = list_input_images()
        for i, img in enumerate(input_images[:20], 1):
            print(f"  {i:2d}. {img}")
        if len(input_images) > 20:
            print(f"  ... ë° {len(input_images) - 20}ê°œ ë”")
        return None
    
    # ì„ë² ë”© íŒŒì¼ í™•ì¸
    if not os.path.isfile(FEATURES_NPY) or not os.path.isfile(PATHS_NPY):
        print("âŒ train í´ë”ì˜ ì„ë² ë”© íŒŒì¼ì„ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.")
        print("   python embeddings_huge.py")
        return None
    
    # ìƒí’ˆ ì •ë³´ ë¡œë“œ ì‹œê°„ ì¸¡ì •
    products_start = time.time()
    products_dict: Dict[str, Any] = load_products_info()
    products_time = time.time() - products_start
    
    # ì„ë² ë”© íŒŒì¼ ë¡œë“œ ì‹œê°„ ì¸¡ì •
    files_start = time.time()
    try:
        print("ğŸ“‚ ì„ë² ë”© íŒŒì¼ ë¡œë“œ ì¤‘...")
        feats: np.ndarray = np.load(FEATURES_NPY).astype("float32")
        paths: np.ndarray = np.load(PATHS_NPY, allow_pickle=True)
        
        if feats.ndim != 2 or feats.shape[0] != len(paths):
            raise ValueError("features/paths íŒŒì¼ í¬ê¸°ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        print(f"âœ… ì„ë² ë”© íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {feats.shape[0]}ê°œ ë²¡í„°, {feats.shape[1]}ì°¨ì›")
            
    except Exception as e:
        print(f"âŒ ì„ë² ë”© íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    files_time = time.time() - files_start
    
    # ëª¨ë¸ ë¡œë“œ ì‹œê°„ ì¸¡ì •
    model_start = time.time()
    device: torch.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸  Device: {device}")
    
    try:
        print("ğŸ”§ OpenCLIP ëª¨ë¸ ë¡œë“œ ì¤‘...")
        print(f"   ëª¨ë¸: {MODEL_NAME}")
        model, transforms = load_model(MODEL_NAME, device) # ì´ í•¨ìˆ˜ê°€ ë¯¸ë¦¬ ë°œë™ë¼ìˆì–´ì•¼ í•¨.
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    model_time = time.time() - model_start
    
    # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
    print(f"ğŸ” '{image_name}' ì´ë¯¸ì§€ë¡œ ìœ ì‚¬ë„ ê²€ìƒ‰ ì¤‘... (ìƒìœ„ {TOPK}ê°œ ê²°ê³¼)")
    results, embedding_time, similarity_time = search_similar_images(query_image_path, feats, paths, model, transforms, device, TOPK)
    
    if results:
        print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼ ë°œê²¬")
        
        # ì‹œê°„ ë¶„ì„ ì¶œë ¥
        print(f"\nâ±ï¸  ìƒì„¸ ì‹œê°„ ë¶„ì„:")
        print(f"   ğŸ“Š ì„ë² ë”© ìƒì„± ì‹œê°„: {embedding_time:.3f}ì´ˆ")
        print(f"   ğŸ” ìœ ì‚¬ë„ ê³„ì‚° ì‹œê°„: {similarity_time:.3f}ì´ˆ")
        print(f"   ğŸ¤– ëª¨ë¸ ë¡œë“œ ì‹œê°„: {model_time:.3f}ì´ˆ")
        print(f"   ğŸ“ íŒŒì¼ ë¡œë“œ ì‹œê°„: {files_time:.3f}ì´ˆ")
        print(f"   ğŸ’° ìƒí’ˆ ì •ë³´ ë¡œë“œ ì‹œê°„: {products_time:.3f}ì´ˆ")
        
        # ê°€ê²© ì •ë³´ë¥¼ ê²°ê³¼ì— ì¶”ê°€
        for result in results:
            result['price'] = get_product_info_from_path(str(result['path']), products_dict)['retail_price']
        
        if return_results:
            # top1 ê²°ê³¼ë§Œ JSON í˜•íƒœë¡œ ë¦¬í„´
            top1_result = results[0]  # ê°€ì¥ ìœ ì‚¬í•œ ì´ë¯¸ì§€ (rank=1)
            price_info: Dict[str, Any] = get_product_info_from_path(str(top1_result['path']), products_dict)
            
            # ê²½ë¡œì—ì„œ í´ë”ëª… ì¶”ì¶œ
            path_parts = str(top1_result['path']).replace('\\', '/').split('/')
            folder_name = path_parts[-2] if len(path_parts) > 1 else "ì•Œ ìˆ˜ ì—†ìŒ"
            
            # JSON í˜•íƒœë¡œ top1 ê²°ê³¼ êµ¬ì„±
            top1_json = {
                "similar_toy_name": folder_name,
                "similar_image_path": str(top1_result['path']),
                "similar_retail_price": price_info['retail_price'] if price_info['retail_price'] != 'ê°€ê²© ì •ë³´ ì—†ìŒ' else 0,
                "similar_used_price": int(price_info['used_price_avg']) if price_info['used_price_avg'] != 'ì¤‘ê³ ê°€ ì •ë³´ ì—†ìŒ' else 0
            }
            
            return top1_json
        else:
            # ì‹œê°í™” í¬í•¨
            visualize_search_results_with_query(query_image_path, results, products_dict)
            return None
    else:
        print("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

# ==================== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ====================

def get_search_results_only(image_name: str) -> Optional[Dict[str, Union[str, int]]]:
    """
    ì´ë¯¸ì§€ ê²€ìƒ‰ ê²°ê³¼ë§Œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ (ì‹œê°í™” ì œì™¸)
    
    ì…ë ¥:
        image_name (str): ê²€ìƒ‰í•  ì´ë¯¸ì§€ íŒŒì¼ëª…
    
    ì¶œë ¥:
        Optional[Dict[str, Union[str, int]]]: top1 ê²€ìƒ‰ ê²°ê³¼ JSON
    """
    print(f"ğŸ” {image_name} ê²€ìƒ‰ ì‹œì‘ (ê²°ê³¼ë§Œ ë°˜í™˜)")
    return search_by_image_name(image_name, return_results=True)

def test_search() -> Optional[Dict[str, Union[str, int]]]:
    """
    ê²€ìƒ‰ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
    
    ì…ë ¥: ì—†ìŒ
    
    ì¶œë ¥:
        Optional[Dict[str, Union[str, int]]]: í…ŒìŠ¤íŠ¸ ê²°ê³¼ JSON
    """
    print("ğŸ§ª ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # input í´ë”ì˜ ì´ë¯¸ì§€ í™•ì¸
    input_images: List[str] = list_input_images()
    if not input_images:
        print("âŒ input í´ë”ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    print(f"ğŸ“ input í´ë”ì—ì„œ {len(input_images)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    
    # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸
    test_image: str = input_images[0]
    print(f"ğŸ” í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {test_image}")
    
    # ê²€ìƒ‰ ì‹¤í–‰
    results: Optional[Dict[str, Union[str, int]]] = get_search_results_only(test_image)
    
    if results:
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ! Top1 ê²°ê³¼ JSON ë°˜í™˜")
        return results
    else:
        print("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return None

def show_image(image_path: str, title: Optional[str] = None, figsize: Tuple[int, int] = (5, 3)) -> None:
    """
    ì´ë¯¸ì§€ë¥¼ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜
    
    ì…ë ¥:
        image_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        title (Optional[str]): ì´ë¯¸ì§€ ì œëª©
        figsize (Tuple[int, int]): ê·¸ë˜í”„ í¬ê¸°
    
    ì¶œë ¥: ì—†ìŒ (matplotlib ê·¸ë˜í”„ í‘œì‹œ)
    """
    try:
        img: Image.Image = Image.open(image_path)
        plt.figure(figsize=figsize)
        plt.imshow(img)
        plt.axis('off')
        if title:
            plt.title(title)
        else:
            plt.title(image_path)
        plt.show()
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")

def clear_gpu_memory() -> None:
    """
    GPU ë©”ëª¨ë¦¬ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
    
    ì…ë ¥: ì—†ìŒ
    
    ì¶œë ¥: ì—†ìŒ
    """
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        print("ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
    
    gc.collect()
    print("ğŸ§¹ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")

def check_gpu_memory() -> Tuple[float, float, float]:
    """
    GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•©ë‹ˆë‹¤.
    
    ì…ë ¥: ì—†ìŒ
    
    ì¶œë ¥:
        Tuple[float, float, float]: (í• ë‹¹ëœ ë©”ëª¨ë¦¬, ì˜ˆì•½ëœ ë©”ëª¨ë¦¬, ì´ ë©”ëª¨ë¦¬) (GB ë‹¨ìœ„)
    """
    if torch.cuda.is_available():
        allocated: float = torch.cuda.memory_allocated() / 1024**3  # GB
        reserved: float = torch.cuda.memory_reserved() / 1024**3    # GB
        total: float = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB
        
        # print(f"ğŸ–¥ï¸  GPU ë©”ëª¨ë¦¬ ìƒíƒœ:")
        # print(f"   í• ë‹¹ë¨: {allocated:.2f} GB")
        # print(f"   ì˜ˆì•½ë¨: {reserved:.2f} GB")
        # print(f"   ì´ ìš©ëŸ‰: {total:.2f} GB")
        # print(f"   ì‚¬ìš© ê°€ëŠ¥: {total - reserved:.2f} GB")
        
        return allocated, reserved, total
    else:
        print("ğŸ’» GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return 0.0, 0.0, 0.0

# ==================== ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ ====================

if __name__ == "__main__":
    # check_gpu_memory()
    # clear_gpu_memory()
    
    # ì˜ˆì‹œ ê²€ìƒ‰ ì‹¤í–‰ (test í´ë”ì˜ ì´ë¯¸ì§€ë¡œ train í´ë” ê²€ìƒ‰)
    t0 = time.time()
    print("ğŸš€ dinov2-large ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹œì‘")
    # print(f"ğŸ“ ê²€ìƒ‰ ëŒ€ìƒ: {INPUT_DIR} í´ë”")
    # print(f"ğŸ“Š ë¹„êµ ëŒ€ìƒ: {USED_DIR} í´ë” (OpenCLIP ì„ë² ë”©)")
    # print(f"ğŸ”§ ëª¨ë¸: {MODEL_NAME}")
    # print(f"ğŸ“ ì„ë² ë”© ì°¨ì›: 1024ì°¨ì›")
    print("=" * 80)
    
    # ì—ì´ì „íŠ¸ì— ë„˜ê²¨ì¤„ ë¦¬í„´ê°’
    result = search_by_image_name("thunder_0734.webp", return_results=True)
    print("=" * 80)
    print("ğŸ” ê²€ìƒ‰ ê²°ê³¼ JSON:")
    print(result)
    print("=" * 80)
    
    total_time = time.time() - t0
    
    print(f"ğŸ¯ ì´ ì†Œìš” ì‹œê°„: {total_time:.3f}ì´ˆ")
    print("=" * 80)
    
    # clear_gpu_memory()
    exit()