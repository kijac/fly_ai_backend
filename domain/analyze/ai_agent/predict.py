# predict.py  (Top-1 ìœ ì‚¬ë„ë§Œ ì‚¬ìš© / ë§ˆì§€ë§‰ 2ë‹¨ê³„ ê²½ë¡œë¡œ ì‹ í’ˆ ì´ë¯¸ì§€ íƒìƒ‰ / CSV: product_name, retail_price, used_price_avg, retail_link)
import os
import csv
import re
import json
from typing import Dict, Optional, List

import numpy as np
from PIL import Image

import torch
from transformers import CLIPProcessor, CLIPModel

from dotenv import load_dotenv

load_dotenv()

# ======================= ê²½ë¡œ ì„¤ì • (ìƒëŒ€ê²½ë¡œ ìš°ì„ ) =======================
# í”„ë¡œì íŠ¸ ë£¨íŠ¸(ì´ íŒŒì¼ ê¸°ì¤€) ì¶”ì •
ROOT_DIR = os.path.dirname(os.path.abspath(__file__))

def _env_or_join(env_key: str, default_rel: str) -> str:
    v = os.getenv(env_key)
    if v and os.path.exists(v):
        return v
    p = os.path.join(ROOT_DIR, default_rel)
    return p

# í…ŒìŠ¤íŠ¸ ì…ë ¥ ì´ë¯¸ì§€ëŠ” test/ ì•„ë˜ ê²½ë¡œ (ì‚¬ìš©ì ì…ë ¥ ì „ìš©)
IMAGE_PATH   = _env_or_join("IMAGE_PATH",   os.path.join("test", "í—¬ë¡œì¹´ë´‡_ë¡œë“œì„¸ì´ë²„", "thunder_0074.webp"))

# ì¸ë±ìŠ¤ëŠ” "train" ë°ì´í„°ë¡œ ìƒì„±ë¨
FEATURES_NPY = _env_or_join("FEATURES_NPY", os.path.join("toys_index", "train_features_large_patch14-336.npy"))
PATHS_NPY    = _env_or_join("PATHS_NPY",    os.path.join("toys_index", "train_paths_large_patch14-336.npy"))

# CLIP ê±°ëŒ€(336) ëª¨ë¸
MODEL_NAME   = os.getenv("CLIP_MODEL_NAME", "openai/clip-vit-large-patch14-336")

# ì‹ í’ˆ(ë¹„êµ ê¸°ì¤€) ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ëŠ” ë² ì´ìŠ¤ í´ë” (train)
# paths.npyì˜ ì›ë³¸ ê²½ë¡œì—ì„œ ë§ˆì§€ë§‰ ë‘ íŒŒíŠ¸ <í´ë”>/<íŒŒì¼>ì„ ì¶”ì¶œí•˜ì—¬ ì—¬ê¸° ì•„ë˜ì—ì„œ ì°¾ìŒ
IMAGE_BASE_DIR = _env_or_join("IMAGE_BASE_DIR", "train")

# CSV(ì‹ ê·œ ìŠ¤í‚¤ë§ˆ): product_name, retail_price(ì‹ í’ˆê°€), used_price_avg(ì¤‘ê³  í‰ê· ê°€), retail_link(ì˜µì…˜)
PRODUCTS_INFO_CSV  = _env_or_join("PRODUCTS_INFO_CSV", "carbot_data_final.csv")
COL_PRODUCT_NAME   = "product_name"
COL_RETAIL_PRICE   = "retail_price"
COL_USED_AVG       = "used_price_avg"
COL_RETAIL_LINK    = "retail_link"

# ê¸°íƒ€
NORMALIZE_FILENAMES = True
TOPK = 1  # í˜¸í™˜ì„±ìš© ìƒìˆ˜ (ì™¸ë¶€ì—ì„œ import)
# =======================================================================


# ----------------------- ë¬¸ìì—´ ì •ê·œí™” -----------------------
def _norm_name(path_or_name: str) -> str:
    name = os.path.basename(str(path_or_name)).strip()
    return name.lower() if NORMALIZE_FILENAMES else name

def _norm_key(s: str) -> str:
    s = (s or "").strip().lower()
    s = os.path.splitext(s)[0]  # í™•ì¥ì ì œê±°
    s = s.replace("_", " ").replace("-", " ")
    s = re.sub(r"\s+", " ", s)
    return s

def _last2_relpath(p: str) -> str:
    """ê²½ë¡œì˜ ë§ˆì§€ë§‰ ë‘ íŒŒíŠ¸ë¥¼ '<dir>/<file>' í˜•íƒœë¡œ ë°˜í™˜. íŒŒíŠ¸ê°€ 1ê°œë©´ íŒŒì¼ëª…ë§Œ."""
    p = os.path.normpath(str(p))
    parts = re.split(r"[\\/]+", p)
    if len(parts) >= 2:
        return os.path.join(parts[-2], parts[-1])
    return parts[-1]

def _parent_dir_name(p: str) -> str:
    p = os.path.normpath(str(p))
    return os.path.basename(os.path.dirname(p))


# ----------------------- CSV ì¹´íƒˆë¡œê·¸ ë¡œë“œ -----------------------
def _to_int_price(x) -> Optional[int]:
    x = str(x or "").replace(",", "").replace("ì›", "").strip()
    if not re.search(r"[0-9]", x):
        return None
    try:
        return int(float(x))
    except ValueError:
        digits = "".join(ch for ch in x if x and ch.isdigit())
        return int(digits) if digits else None

def _build_catalog(csv_path: str):
    """CSV: product_name, retail_price, used_price_avg, (retail_link)"""
    if not os.path.isfile(csv_path):
        return {}, {}, {}, {}

    encodings = ("utf-8-sig", "utf-8", "cp949")
    last_err = None
    for enc in encodings:
        try:
            with open(csv_path, "r", encoding=enc, newline="") as f:
                reader = csv.DictReader(f)
                fields = set(reader.fieldnames or [])
                need = {COL_PRODUCT_NAME, COL_RETAIL_PRICE, COL_USED_AVG}
                if not need.issubset(fields):
                    raise KeyError(f"CSV columns missing: need {need}, got {fields}")

                retail_by_key: Dict[str, int] = {}
                usedavg_by_key: Dict[str, int] = {}
                name_by_key: Dict[str, str] = {}
                link_by_key: Dict[str, str] = {}

                for row in reader:
                    name = (row.get(COL_PRODUCT_NAME) or "").strip()
                    if not name:
                        continue
                    key = _norm_key(name)
                    rp = _to_int_price(row.get(COL_RETAIL_PRICE))
                    up = _to_int_price(row.get(COL_USED_AVG))
                    if rp is not None:
                        retail_by_key[key] = rp
                    if up is not None:
                        usedavg_by_key[key] = up
                    name_by_key[key] = name
                    if COL_RETAIL_LINK in fields:
                        link_by_key[key] = (row.get(COL_RETAIL_LINK) or "").strip()
                return retail_by_key, usedavg_by_key, name_by_key, link_by_key
        except UnicodeDecodeError as e:
            last_err = e
            continue
    raise RuntimeError(f"CSV ì¸ì½”ë”© ì‹¤íŒ¨: {last_err}")


# ----------------------- CLIP ì„ë² ë”© -----------------------
# ì „ì—­ ë³€ìˆ˜ë¡œ CLIP ëª¨ë¸ ê´€ë¦¬ (í•œ ë²ˆë§Œ ë¡œë”©í•˜ê³  ì¬ì‚¬ìš©)
_global_model = None
_global_processor = None
_global_device = None

def get_or_load_model(model_name: str = MODEL_NAME):
    """CLIP ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë”©í•˜ê³  ì¬ì‚¬ìš©"""
    global _global_model, _global_processor, _global_device
    
    if _global_model is None:
        # GPU ì‚¬ìš© ê°•ì œ ì„¤ì •
        if torch.cuda.is_available():
            _global_device = torch.device("cuda:0")
            print(f"GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}")
        else:
            _global_device = torch.device("cpu")
            print("GPU ì‚¬ìš© ë¶ˆê°€ëŠ¥, CPU ì‚¬ìš©")
        
        _global_model = CLIPModel.from_pretrained(model_name).to(_global_device)
        _global_processor = CLIPProcessor.from_pretrained(model_name)
        _global_model.eval()
        
        # GPU ë©”ëª¨ë¦¬ ìµœì í™”
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            print(f"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {torch.cuda.memory_allocated(0) / 1024**2:.1f}MB")
        
        print(f"CLIP ëª¨ë¸ ë¡œë”© ì™„ë£Œ (device: {_global_device})")
    
    return _global_model, _global_processor, _global_device

def load_model(model_name: str, device: torch.device):
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜"""
    return get_or_load_model(model_name)

def clear_gpu_memory():
    """GPU ë©”ëª¨ë¦¬ ì •ë¦¬"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print("GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")

def embed_image(model, processor, img_path, device) -> np.ndarray:
    image = Image.open(img_path).convert("RGB")
    with torch.no_grad():
        inputs = processor(images=image, return_tensors="pt").to(device)
        feat = model.get_image_features(**inputs)
        feat = feat / feat.norm(p=2, dim=-1, keepdim=True)
    return feat.cpu().numpy().astype("float32").flatten()

def embed_texts(model, processor, texts: List[str], device) -> np.ndarray:
    with torch.no_grad():
        inputs = processor(text=texts, return_tensors="pt", padding=True, truncation=True).to(device)
        feats = model.get_text_features(**inputs)
        feats = feats / feats.norm(p=2, dim=-1, keepdim=True)
    return feats.cpu().numpy().astype("float32")


# ----------------------- ê²½ë¡œ/IO -----------------------
def resolve_from_last2(original_path: str, base_dir: Optional[str]) -> Optional[str]:
    """
    base_dir/<last-folder>/<filename> ìš°ì„  íƒìƒ‰, ì—†ìœ¼ë©´ base_dir/<filename> í´ë°±.
    """
    if not base_dir:
        return None
    last2 = _last2_relpath(original_path)                 # <dir>/<file> ë˜ëŠ” <file>
    cand = os.path.join(base_dir, last2)
    if os.path.isfile(cand):
        return cand
    just_file = os.path.join(base_dir, os.path.basename(original_path))
    if os.path.isfile(just_file):
        return just_file
    return None

def _read_bytes_or_none(path: Optional[str]) -> Optional[bytes]:
    if not path or not os.path.isfile(path):
        return None
    with open(path, "rb") as f:
        return f.read()


# ----------------------- ìœ ì‚¬ë„ ê²€ìƒ‰ (Top-1) -----------------------
def similar_search_top1(query_img: str, feats_npy: str, paths_npy: str,
                        model_name: str) -> dict:
    import time
    clip_start_time = time.time()
    
    if not os.path.isfile(query_img):
        raise FileNotFoundError(f"IMAGE_PATH not found: {query_img}")
    if not os.path.isfile(feats_npy) or not os.path.isfile(paths_npy):
        raise FileNotFoundError("features/paths npy í•„ìš”")

    feats = np.load(feats_npy).astype("float32")
    paths = np.load(paths_npy, allow_pickle=True)
    if feats.ndim != 2 or feats.shape[0] != len(paths):
        raise ValueError("features/paths í¬ê¸° ë¶ˆì¼ì¹˜")

    model, processor, device = get_or_load_model(model_name)
    
    clip_end_time = time.time()
    clip_time = clip_end_time - clip_start_time
    print(f"ğŸ” CLIP ìœ ì‚¬ë„ ê²€ìƒ‰ ì™„ë£Œ: {clip_time:.2f}ì´ˆ")

    q = embed_image(model, processor, query_img, device)
    q = q / (np.linalg.norm(q) + 1e-9)
    feats = feats / (np.linalg.norm(feats, axis=1, keepdims=True) + 1e-9)

    sims = feats @ q
    i = int(np.argmax(sims))
    return {
        "rank": 1,
        "path": str(paths[i]),                                  # ì›ë³¸ ê²½ë¡œ(ì¸ë±ìŠ¤ ìƒì„± ì‹œ)
        "filename": _norm_name(os.path.basename(str(paths[i]))),
        "sim": float(sims[i]),
    }


# ----------------------- ë§¤ì¹­ ìœ í‹¸ -----------------------
def _best_match_key_by_tokens(tokens: List[str], keys: List[str]) -> Optional[str]:
    """ì—¬ëŸ¬ í† í°(íŒŒì¼ëª… stem, ìƒìœ„ í´ë”ëª… ë“±)ìœ¼ë¡œ product_name ë§¤ì¹­ ì‹œë„."""
    if not keys:
        return None
    # 1) ì™„ì „ ì¼ì¹˜ ìš°ì„ 
    n_tokens = [_norm_key(t) for t in tokens if t]
    for t in n_tokens:
        if t in keys:
            return t
    # 2) ë¶€ë¶„ í¬í•¨(ê¸´ í‚¤ ìš°ì„ )
    cands = []
    for t in n_tokens:
        cands += [k for k in keys if (t in k or k in t)]
    if cands:
        return sorted(set(cands), key=len, reverse=True)[0]
    return None

def _best_match_key_by_clip(query_img_path: str, name_by_key: Dict[str, str]) -> Optional[str]:
    """íŒŒì¼ëª…/í´ë”ëª… ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ: CLIP ì´ë¯¸ì§€â†”í…ìŠ¤íŠ¸ ë§¤ì¹­ìœ¼ë¡œ product_name ì°¾ê¸°"""
    if not name_by_key:
        return None
    model, processor, device = get_or_load_model(MODEL_NAME)
    qvec = embed_image(model, processor, query_img_path, device)
    qvec = qvec / (np.linalg.norm(qvec) + 1e-9)

    keys = list(name_by_key.keys())
    names = [name_by_key[k] for k in keys]
    tfeats = embed_texts(model, processor, names, device)   # (N, D), ì´ë¯¸ ì •ê·œí™”ë¨
    sims = tfeats @ qvec                                    # (N,)
    idx = int(np.argmax(sims))
    return keys[idx] if len(keys) else None


# ----------------------- ë©”ì¸ íŒŒì´í”„ë¼ì¸ -----------------------
def run_sameitem_price(
    image_path: str = IMAGE_PATH,
    feats_npy: str = FEATURES_NPY,
    paths_npy: str = PATHS_NPY,
    csv_path: str = PRODUCTS_INFO_CSV,
    base_dir: str = IMAGE_BASE_DIR,
    topk: int = TOPK,    # í˜¸í™˜ì„± íŒŒë¼ë¯¸í„°(ë‚´ë¶€ì—ì„œëŠ” Top-1 ê³ ì •)
) -> dict:
    # 0) ì¹´íƒˆë¡œê·¸ ë¡œë“œ
    retail_by_key, usedavg_by_key, name_by_key, link_by_key = _build_catalog(csv_path)

    # 1) ìœ ì‚¬ë„ Top-1
    top1 = similar_search_top1(image_path, feats_npy, paths_npy, MODEL_NAME)
    orig_path = top1["path"]
    fname     = top1["filename"]
    stem      = os.path.splitext(fname)[0]
    parent    = _parent_dir_name(orig_path)

    # 2) â˜… ì‹ í’ˆ(ë¹„êµ ê¸°ì¤€) ì´ë¯¸ì§€ ê²½ë¡œ: base_dir/<last-folder>/<file> â†’ ì—†ìœ¼ë©´ base_dir/<file>
    ref_new_path = resolve_from_last2(orig_path, base_dir)

    # 3) product_name ë§¤ì¹­
    all_keys = list(name_by_key.keys())
    match_key = _best_match_key_by_tokens([stem, parent], all_keys)
    reason = "tokens-match"
    if not match_key:
        match_key = _best_match_key_by_clip(image_path, name_by_key)
        reason = "clip-text-match" if match_key else "no-catalog-match"

    if not match_key:
        return {
            "status": "unavailable",
            "matched_count": 0,
            "matched_files": [],
            "matched_prices": [],
            "baseline_price": None,
            "retail_price": None,
            "toy_name": None,
            "retail_link": None,
            "ref_new_image_path": ref_new_path,
            "ref_new_image_bytes": _read_bytes_or_none(ref_new_path),
            # ì¤‘ê³  ì´ë¯¸ì§€ëŠ” ë¹„êµì— ì‚¬ìš©í•˜ì§€ ì•ŠìŒ(ëª…ì‹œì ìœ¼ë¡œ None)
            "ref_image_path": None,
            "ref_image_bytes": None,
            "ref_selection_reason": f"top1-{reason}",
            "same_flags": [],
            "candidates": [{ **top1, "resolved_path": ref_new_path or "", "title": None }],
        }

    toy_name = name_by_key.get(match_key)
    used_avg = usedavg_by_key.get(match_key)
    retail   = retail_by_key.get(match_key)

    if used_avg is None and retail is None:
        return {
            "status": "unavailable",
            "matched_count": 0,
            "matched_files": [],
            "matched_prices": [],
            "baseline_price": None,
            "retail_price": None,
            "toy_name": toy_name,
            "retail_link": link_by_key.get(match_key),
            "ref_new_image_path": ref_new_path,
            "ref_new_image_bytes": _read_bytes_or_none(ref_new_path),
            "ref_image_path": None,
            "ref_image_bytes": None,
            "ref_selection_reason": f"top1-{reason}-no-prices",
            "same_flags": [],
            "candidates": [{ **top1, "resolved_path": ref_new_path or "", "title": toy_name }],
        }

    matched_count = 1 if used_avg is not None else 0
    matched_files = [fname] if matched_count == 1 else []
    matched_prices = [int(used_avg)] if matched_count == 1 else []

    return {
        "status": "ok",
        "matched_count": matched_count,
        "matched_files": matched_files,
        "matched_prices": matched_prices,
        "baseline_price": int(used_avg) if used_avg is not None else None,  # ì¤‘ê³  ê¸°ì¤€ê°€
        "retail_price": int(retail) if retail is not None else None,        # ì‹ ì œí’ˆê°€
        "toy_name": toy_name,
        "retail_link": link_by_key.get(match_key),
        # â˜… ë¹„êµ ê¸°ì¤€: ì‹ í’ˆ ì´ë¯¸ì§€(trainì—ì„œ last-2 ê²½ë¡œë¡œ íƒìƒ‰)
        "ref_new_image_path": ref_new_path,
        "ref_new_image_bytes": _read_bytes_or_none(ref_new_path),
        # ì¤‘ê³  ì°¸ì¡°ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        "ref_image_path": None,
        "ref_image_bytes": None,
        "ref_selection_reason": f"top1-{reason}-last2",
        "same_flags": [],
        "candidates": [{ **top1, "resolved_path": ref_new_path or "", "title": toy_name }],
    }


# ----------------------- ìŠ¤í¬ë¦½íŠ¸ ë‹¨ë… ì‹¤í–‰ -----------------------
if __name__ == "__main__":
    out = run_sameitem_price()
    summary = {
        "status": out.get("status"),
        "toy_name": out.get("toy_name"),
        "baseline_price": out.get("baseline_price"),
        "retail_price": out.get("retail_price"),
        "matched_files": out.get("matched_files"),
        "ref_new_image_path": out.get("ref_new_image_path"),
        "ref_selection_reason": out.get("ref_selection_reason"),
        "top1_sim": (out.get("candidates") or [{}])[0].get("sim"),
    }
    print(json.dumps(summary, ensure_ascii=False))
