# ai_agent_output.py  (ìµœì¢… JSON: toy_name, retail_price, purchase_price, soil, damage, toy_type, material)
import os
import re
import json
import base64
import argparse
import tempfile
import atexit
from typing import List, Optional

import pandas as pd
import ntpath  # for Windows-style basename

# === (1) ê¸°ì¤€ê°€ íŒŒì´í”„ë¼ì¸ ===
from predict import (
    run_sameitem_price,
    IMAGE_BASE_DIR, FEATURES_NPY, PATHS_NPY, PRODUCTS_INFO_CSV, TOPK, IMAGE_PATH
)

# === (2) ìƒíƒœ íŒë³„ ì—ì´ì „íŠ¸ ===
from ai_agent.supervisor_agent import SupervisorAgent


# -----------------------
# ìœ í‹¸
# -----------------------
def _read_bytes_or_none(p: Optional[str]) -> Optional[bytes]:
    if not p:
        return None
    with open(p, "rb") as f:
        return f.read()

def get_title_from_csv(csv_path: Optional[str], ref_image_path: Optional[str]) -> str:
    """
    (ë°±ì—…ìš©) ê³¼ê±° CSV(title, price, thumbnail_filename...) ìŠ¤í‚¤ë§ˆ ëŒ€ë¹„ìš©.
    ì‹ ê·œ ìŠ¤í‚¤ë§ˆì—ì„œëŠ” predictê°€ toy_nameì„ ì§ì ‘ ì£¼ë¯€ë¡œ ë³´í†µì€ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ.
    """
    if not csv_path or not ref_image_path or not os.path.exists(csv_path):
        return "ë¶ˆëª…"
    try:
        try:
            df = pd.read_csv(csv_path)
        except Exception:
            df = pd.read_csv(csv_path, encoding="utf-8-sig", on_bad_lines="skip")
    except Exception:
        return "ë¶ˆëª…"

    if df is None or df.empty:
        return "ë¶ˆëª…"

    # ì‹ ê·œ ìŠ¤í‚¤ë§ˆì¼ ê²½ìš° product_nameì´ ìˆìœ¼ë©´ íŒŒì¼ëª…ìœ¼ë¡œ ë§¤ì¹­ ì‹œë„í•˜ì§€ ì•Šê³  ë¶ˆëª… ì²˜ë¦¬
    if "product_name" in df.columns:
        return "ë¶ˆëª…"

    if "thumbnail_filename" not in df.columns or "title" not in df.columns:
        return "ë¶ˆëª…"

    ref_base = ntpath.basename(str(ref_image_path)).strip().lower()
    ser = df["thumbnail_filename"].astype(str).str.strip().str.lower()
    mask = ser == ref_base
    if mask.any():
        return str(df.loc[mask, "title"].iloc[0]).strip()
    # í™•ì¥ì ì œê±° ë§¤ì¹­ ë³´ì¡°
    ref_stem = os.path.splitext(ref_base)[0]
    mask2 = ser.apply(lambda x: os.path.splitext(x)[0]) == ref_stem
    if mask2.any():
        return str(df.loc[mask2, "title"].iloc[0]).strip()
    return "ë¶ˆëª…"


def _pick_ref_bytes(baseline: dict) -> Optional[bytes]:
    """ìƒˆ predictê°€ 'ref_new_image_bytes'ë¥¼ ì œê³µí•˜ë©´ ê·¸ê±¸ ì‚¬ìš©."""
    return baseline.get("ref_new_image_bytes") or baseline.get("ref_image_bytes")

def _pick_ref_path(baseline: dict) -> Optional[str]:
    """ê²½ë¡œë„ ë™ì¼í•œ ìš°ì„ ìˆœìœ„ë¡œ ì„ íƒ."""
    return baseline.get("ref_new_image_path") or baseline.get("ref_image_path")


# -----------------------
# ìƒíƒœ íŒë³„
# -----------------------
def run_condition_agents(
    front_path: str,
    left_path: Optional[str] = None,
    rear_path: Optional[str] = None,
    right_path: Optional[str] = None,
    ref_image_bytes: Optional[bytes] = None,  # ê¸°ì¤€ ì´ë¯¸ì§€ 1ì¥ (ì‹ ìƒí’ˆ)
) -> dict:
    front_b = _read_bytes_or_none(front_path)
    left_b  = _read_bytes_or_none(left_path)  if left_path  else front_b
    rear_b  = _read_bytes_or_none(rear_path)  if rear_path  else front_b
    right_b = _read_bytes_or_none(right_path) if right_path else front_b

    if ref_image_bytes is None:
        return {
            "ì¥ë‚œê° ì¢…ë¥˜": "others",
            "ì¬ë£Œ": "unknown",
            "ì˜¤ì—¼ë„": "ë¶ˆëª…",
            "íŒŒì†": "ë¶ˆëª…",
            "í¬ê¸°": None,
            "ê±´ì „ì§€ ì—¬ë¶€": None,
            "í† í° ì‚¬ìš©ëŸ‰": {"total": 0},
        }

    sup = SupervisorAgent()
    result = sup.process(front_b, left_b, rear_b, right_b, ref_image_bytes)

    out = {
        "ì¥ë‚œê° ì¢…ë¥˜": result.get("ì¥ë‚œê° ì¢…ë¥˜", "others"),
        "ì¬ë£Œ": result.get("ì¬ë£Œ", "unknown"),
        "ì˜¤ì—¼ë„": result.get("ì˜¤ì—¼ë„", "ë¶ˆëª…"),
        "íŒŒì†": result.get("íŒŒì†", "ë¶ˆëª…"),
        "í¬ê¸°": result.get("í¬ê¸°"),
        "ê±´ì „ì§€ ì—¬ë¶€": result.get("ê±´ì „ì§€ ì—¬ë¶€"),
        "í† í° ì‚¬ìš©ëŸ‰": result.get("í† í° ì‚¬ìš©ëŸ‰", {}),
    }
    # DamageAgentê°€ ì£¼ëŠ” ë“±ê¸‰/ë³´ì¡° í•„ë“œ ê·¸ëŒ€ë¡œ ì „ë‹¬
    if "íŒŒì† ìƒëŒ€ë“±ê¸‰" in result:
        out["íŒŒì† ìƒëŒ€ë“±ê¸‰"] = result["íŒŒì† ìƒëŒ€ë“±ê¸‰"]   # 'A'..'E'
    if "relative_steps" in result:
        out["íŒŒì† ë‹¨ê³„ì°¨"] = result["relative_steps"]    # 0..4 (ìˆë‹¤ë©´)
    if "íŒŒì† ì ìˆ˜(ì¤‘ê³ )" in result:
        out["íŒŒì† ì ìˆ˜(ì¤‘ê³ )"] = result["íŒŒì† ì ìˆ˜(ì¤‘ê³ )"]  # 0..4 (ìˆë‹¤ë©´)
    if "íŒŒì† ì ìˆ˜(ì‹ í’ˆ)" in result:
        out["íŒŒì† ì ìˆ˜(ì‹ í’ˆ)"] = result["íŒŒì† ì ìˆ˜(ì‹ í’ˆ)"]  # 0..4 (ìˆë‹¤ë©´)

    # SoilAgent: ë“±ê¸‰/ì ìˆ˜ í•„ë“œ ë°˜ì˜ (ì‹ ê·œ í¬ë§·)
    if "ì˜¤ì—¼ ìƒëŒ€ë“±ê¸‰" in result:
        out["ì˜¤ì—¼ ìƒëŒ€ë“±ê¸‰"] = result["ì˜¤ì—¼ ìƒëŒ€ë“±ê¸‰"]       # 'A'..'E'
    if "ì˜¤ì—¼ ì ìˆ˜(ì¤‘ê³ )" in result:
        out["ì˜¤ì—¼ ì ìˆ˜(ì¤‘ê³ )"] = result["ì˜¤ì—¼ ì ìˆ˜(ì¤‘ê³ )"]   # 0..4
    if "ì˜¤ì—¼ ì ìˆ˜(ì‹ í’ˆ)" in result:
        out["ì˜¤ì—¼ ì ìˆ˜(ì‹ í’ˆ)"] = result["ì˜¤ì—¼ ì ìˆ˜(ì‹ í’ˆ)"]   # 0..4

    # (êµ¬ë²„ì „ í˜¸í™˜) -2..+2ê°€ ìˆìœ¼ë©´ ê°™ì´ ì „ë‹¬
    if "ê¸°ì¤€ ëŒ€ë¹„(ì˜¤ì—¼)" in result:
        out["ê¸°ì¤€ ëŒ€ë¹„(ì˜¤ì—¼)"] = result["ê¸°ì¤€ ëŒ€ë¹„(ì˜¤ì—¼)"]
    return out


# -----------------------
# ë³´ì¡°: -2..+2 â†’ A~E (í˜¸í™˜ìš©)
# -----------------------
def _level_to_grade(level: int) -> str:
    """
    2â†’A, 1â†’B, 0â†’C, -1â†’D, -2â†’E
    """
    try:
        lv = int(level)
    except Exception:
        lv = 0
    if lv >= 2: return "A"
    if lv == 1: return "B"
    if lv == 0: return "C"
    if lv == -1: return "D"
    return "E"  # lv <= -2


# -----------------------
# ë“±ê¸‰(A~E) â†’ ê°€ê²©ë³´ì • ê³„ìˆ˜
# -----------------------
def _grade_to_multiplier(grade: Optional[str]) -> float:
    """
    A(ì‹ í’ˆ ìˆ˜ì¤€)â†’1.00, Bâ†’0.95, Câ†’0.90, Dâ†’0.80, Eâ†’0.65
    """
    g = (grade or "").strip().upper()
    table = {"A": 1.00, "B": 0.95, "C": 0.90, "D": 0.80, "E": 0.65}
    return table.get(g, 0.90)  # ì•Œ ìˆ˜ ì—†ëŠ” ê²½ìš° ë³´ìˆ˜ì ìœ¼ë¡œ C ìˆ˜ì¤€


# -----------------------
# í†µí•© íŒŒì´í”„ë¼ì¸
# -----------------------
def run_full_pipeline(
    query_image_path: str,
    feats_npy: str = FEATURES_NPY,
    paths_npy: str = PATHS_NPY,
    csv_path: str = PRODUCTS_INFO_CSV,
    base_dir: str = IMAGE_BASE_DIR,
    topk: int = TOPK,  # predictê°€ Top-1ë¡œ ê°•ì œí•˜ë”ë¼ë„ ì˜µì…˜ì€ ë‚¨ê²¨ë‘ (í˜¸í™˜)
    left: Optional[str] = None,
    rear: Optional[str] = None,
    right: Optional[str] = None,
) -> dict:
    import time
    start_time = time.time()
    print(f"ğŸš€ AI ë¶„ì„ ì‹œì‘: {query_image_path}")
    baseline = run_sameitem_price(
        image_path=query_image_path,
        feats_npy=feats_npy,
        paths_npy=paths_npy,
        csv_path=csv_path,
        base_dir=base_dir,
        topk=topk,
    )

    ref_bytes = _pick_ref_bytes(baseline)

    if baseline.get("status") != "ok" or not ref_bytes:
        attrs = run_condition_agents(
            front_path=query_image_path,
            left_path=left, rear_path=rear, right_path=right,
            ref_image_bytes=None
        )
        return {
            "ê¸°ì¤€ê°€_status": baseline.get("status"),
            "baseline_price": baseline.get("baseline_price"),
            "retail_price": baseline.get("retail_price"),
            "toy_name": baseline.get("toy_name"),
            "ê¸°ì¤€ê°€_ë§¤ì¹­ê°œìˆ˜": baseline.get("matched_count", 0),
            "ë§¤ì¹­íŒŒì¼": baseline.get("matched_files", []),
            "ë§¤ì¹­ê°€ê²©": baseline.get("matched_prices", []),
            "ì¢…ë¥˜": attrs.get("ì¥ë‚œê° ì¢…ë¥˜"),
            "ì†Œì¬": attrs.get("ì¬ë£Œ"),
            "ì˜¤ì—¼ë„": attrs.get("ì˜¤ì—¼ë„"),
            "íŒŒì†ë„": attrs.get("íŒŒì†"),
            "íŒŒì† ìƒëŒ€ë“±ê¸‰": attrs.get("íŒŒì† ìƒëŒ€ë“±ê¸‰"),
            "íŒŒì† ë‹¨ê³„ì°¨": attrs.get("íŒŒì† ë‹¨ê³„ì°¨"),
            "íŒŒì† ì ìˆ˜(ì¤‘ê³ )": attrs.get("íŒŒì† ì ìˆ˜(ì¤‘ê³ )"),
            "íŒŒì† ì ìˆ˜(ì‹ í’ˆ)": attrs.get("íŒŒì† ì ìˆ˜(ì‹ í’ˆ)"),
            "ì˜¤ì—¼ ìƒëŒ€ë“±ê¸‰": attrs.get("ì˜¤ì—¼ ìƒëŒ€ë“±ê¸‰"),
            "ì˜¤ì—¼ ì ìˆ˜(ì¤‘ê³ )": attrs.get("ì˜¤ì—¼ ì ìˆ˜(ì¤‘ê³ )"),
            "ì˜¤ì—¼ ì ìˆ˜(ì‹ í’ˆ)": attrs.get("ì˜¤ì—¼ ì ìˆ˜(ì‹ í’ˆ)"),
            "í¬ê¸°": attrs.get("í¬ê¸°"),
            "ê±´ì „ì§€": attrs.get("ê±´ì „ì§€ ì—¬ë¶€"),
            "ê¸°ì¤€ ëŒ€ë¹„(ì˜¤ì—¼)": attrs.get("ê¸°ì¤€ ëŒ€ë¹„(ì˜¤ì—¼)"),
            "ì—ì´ì „íŠ¸_í† í°í•©": attrs.get("í† í° ì‚¬ìš©ëŸ‰", {}).get("total", 0),
            "ref_image_path": _pick_ref_path(baseline),          # ê·¸ëŒ€ë¡œ ì „ë‹¬
            "ref_selection_reason": baseline.get("ref_selection_reason"),
            "csv_path": csv_path,
        }

    attrs = run_condition_agents(
        front_path=query_image_path,
        left_path=left, rear_path=rear, right_path=right,
        ref_image_bytes=ref_bytes
    )

    out = {
        "ê¸°ì¤€ê°€_status": baseline.get("status"),
        "baseline_price": baseline.get("baseline_price"),
        "retail_price": baseline.get("retail_price"),
        "toy_name": baseline.get("toy_name"),
        "ê¸°ì¤€ê°€_ë§¤ì¹­ê°œìˆ˜": baseline.get("matched_count", 0),

        "ì¢…ë¥˜": attrs.get("ì¥ë‚œê° ì¢…ë¥˜"),
        "ì†Œì¬": attrs.get("ì¬ë£Œ"),
        "ì˜¤ì—¼ë„": attrs.get("ì˜¤ì—¼ë„"),
        "íŒŒì†ë„": attrs.get("íŒŒì†"),
        "íŒŒì† ìƒëŒ€ë“±ê¸‰": attrs.get("íŒŒì† ìƒëŒ€ë“±ê¸‰"),
        "íŒŒì† ë‹¨ê³„ì°¨": attrs.get("íŒŒì† ë‹¨ê³„ì°¨"),
        "íŒŒì† ì ìˆ˜(ì¤‘ê³ )": attrs.get("íŒŒì† ì ìˆ˜(ì¤‘ê³ )"),
        "íŒŒì† ì ìˆ˜(ì‹ í’ˆ)": attrs.get("íŒŒì† ì ìˆ˜(ì‹ í’ˆ)"),
        "ì˜¤ì—¼ ìƒëŒ€ë“±ê¸‰": attrs.get("ì˜¤ì—¼ ìƒëŒ€ë“±ê¸‰"),
        "ì˜¤ì—¼ ì ìˆ˜(ì¤‘ê³ )": attrs.get("ì˜¤ì—¼ ì ìˆ˜(ì¤‘ê³ )"),
        "ì˜¤ì—¼ ì ìˆ˜(ì‹ í’ˆ)": attrs.get("ì˜¤ì—¼ ì ìˆ˜(ì‹ í’ˆ)"),
        "í¬ê¸°": attrs.get("í¬ê¸°"),
        "ê±´ì „ì§€": attrs.get("ê±´ì „ì§€ ì—¬ë¶€"),

        "ê¸°ì¤€ ëŒ€ë¹„(ì˜¤ì—¼)": attrs.get("ê¸°ì¤€ ëŒ€ë¹„(ì˜¤ì—¼)"),

        "ë§¤ì¹­íŒŒì¼": baseline.get("matched_files", []),
        "ë§¤ì¹­ê°€ê²©": baseline.get("matched_prices", []),

        "ì—ì´ì „íŠ¸_í† í°í•©": attrs.get("í† í° ì‚¬ìš©ëŸ‰", {}).get("total", 0),
        "ref_image_path": _pick_ref_path(baseline),
        "ref_selection_reason": baseline.get("ref_selection_reason"),
        "csv_path": csv_path,
    }
    
    end_time = time.time()
    total_time = end_time - start_time
    print(f"âœ… AI ë¶„ì„ ì™„ë£Œ: {total_time:.2f}ì´ˆ")
    
    return out


# -----------------------
# ì¶”ì²œê°€(ë§¤ì…ê°€) ì‚°ì¶œ â€” íŒŒì†/ì˜¤ì—¼ ëª¨ë‘ A~E ë“±ê¸‰ ì‚¬ìš©
# -----------------------
def _round_to_unit(x: float, unit: int = 100) -> int:
    return int(round(x / unit) * unit)

def estimate_purchase_price_by_grade(
    baseline_price: int,
    *,
    damage_grade: Optional[str],        # 'A'..'E'
    soil_grade: Optional[str],          # 'A'..'E'
    base_bias: float = 0.7
) -> dict:
    dmg_mult  = _grade_to_multiplier(damage_grade)
    soil_mult = _grade_to_multiplier(soil_grade)

    biased_baseline = baseline_price * float(base_bias)
    total_mult = dmg_mult * soil_mult
    raw_price = biased_baseline * total_mult
    recommended = _round_to_unit(raw_price, 100)

    return {
        "recommended_price": int(recommended),
        "effective_multiplier_vs_baseline": round(base_bias * total_mult, 4),
        "damage_multiplier": dmg_mult,
        "soil_multiplier": soil_mult,
    }


# -----------------------
# data URL ì§€ì› (CLI)
# -----------------------
_DATAURL_RE = re.compile(r"^data:(?P<mime>[\w\-/+\.]+)?;base64,(?P<b64>[A-Za-z0-9+/=]+)$")
_TEMP_FILES: List[str] = []

def dataurl_to_bytes(dataurl: Optional[str]) -> Optional[bytes]:
    if not dataurl:
        return None
    m = _DATAURL_RE.match(dataurl.strip())
    if not m:
        return None
    try:
        return base64.b64decode(m.group("b64"))
    except Exception:
        return None

def bytes_to_tempfile(b: bytes, suffix: str = ".jpg") -> str:
    f = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
    f.write(b)
    f.flush()
    f.close()
    _TEMP_FILES.append(f.name)
    return f.name

def _cleanup_tempfiles():
    for p in _TEMP_FILES:
        try:
            os.remove(p)
        except Exception:
            pass
atexit.register(_cleanup_tempfiles)


# -----------------------
# CLI
# -----------------------
def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="ê¸°ì¤€ê°€ + ìƒíƒœíŒë³„ í†µí•© íŒŒì´í”„ë¼ì¸(JSON ì¶œë ¥)")
    # íŒŒì¼ ê²½ë¡œ ì…ë ¥
    parser.add_argument("--query", type=str, default=IMAGE_PATH, help="ë©”ì¸ ì´ë¯¸ì§€(ì•ë©´) - íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--left", type=str, default=None, help="ì™¼ìª½ ì´ë¯¸ì§€ - íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--rear", type=str, default=None, help="ë’·ë©´ ì´ë¯¸ì§€ - íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--right", type=str, default=None, help="ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ - íŒŒì¼ ê²½ë¡œ")

    # data URL ì…ë ¥ (ì›¹/ì•±ì—ì„œ ë°”ë¡œ ì „ë‹¬)
    parser.add_argument("--query-dataurl", type=str, default=None, help="ë©”ì¸ ì´ë¯¸ì§€ data URL (data:image/jpeg;base64,...)")
    parser.add_argument("--left-dataurl", type=str, default=None, help="ì™¼ìª½ ì´ë¯¸ì§€ data URL")
    parser.add_argument("--rear-dataurl", type=str, default=None, help="ë’·ë©´ ì´ë¯¸ì§€ data URL")
    parser.add_argument("--right-dataurl", type=str, default=None, help="ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ data URL")

    parser.add_argument("--feats", type=str, default=FEATURES_NPY, help="features.npy")
    parser.add_argument("--paths", type=str, default=PATHS_NPY, help="paths.npy")
    parser.add_argument("--csv",   type=str, default=PRODUCTS_INFO_CSV, help="ê°€ê²© CSV ê²½ë¡œ")
    parser.add_argument("--base",  type=str, default=IMAGE_BASE_DIR, help="í›„ë³´ ì‹¤ì´ë¯¸ì§€ í´ë”")
    parser.add_argument("--topk",  type=int, default=TOPK, help="ìœ ì‚¬ë„ ê²€ìƒ‰ ìƒìœ„ K (predict ë‚´ë¶€ì—ì„œ Top-1 ê°•ì œ ê°€ëŠ¥)")
    parser.add_argument("--base-bias", type=float, default=0.7, help="ë§¤ì…ê°€ ê¸°ì¤€ê°€ ë°”ì´ì–´ìŠ¤ (ê¸°ë³¸ 0.7)")
    return parser


def main():
    parser = build_parser()
    args = parser.parse_args()

    # data URL ìš°ì„  ì²˜ë¦¬ â†’ ì„ì‹œ ê²½ë¡œ ë³€í™˜
    query_path = args.query
    left_path  = args.left
    rear_path  = args.rear
    right_path = args.right

    if args.query_dataurl:
        qb = dataurl_to_bytes(args.query_dataurl)
        if qb: query_path = bytes_to_tempfile(qb, ".jpg")
    if args.left_dataurl:
        lb = dataurl_to_bytes(args.left_dataurl)
        if lb: left_path = bytes_to_tempfile(lb, ".jpg")
    if args.rear_dataurl:
        rb = dataurl_to_bytes(args.rear_dataurl)
        if rb: rear_path = bytes_to_tempfile(rb, ".jpg")
    if args.right_dataurl:
        rb = dataurl_to_bytes(args.right_dataurl)
        if rb: right_path = bytes_to_tempfile(rb, ".jpg")

    final_json = run_full_pipeline_and_get_final_json(
        query_image_path=query_path,
        feats_npy=args.feats,
        paths_npy=args.paths,
        csv_path=args.csv,
        base_dir=args.base,
        topk=args.topk,
        left=left_path, rear=rear_path, right=right_path,
        base_bias=args.base_bias,
    )
    
    # CLIì—ì„œëŠ” JSON ì¶œë ¥, í•¨ìˆ˜ í˜¸ì¶œì—ì„œëŠ” ë°˜í™˜
    if __name__ == "__main__":
        print(json.dumps(final_json, ensure_ascii=False))
    
    return final_json


def run_full_pipeline_and_get_final_json(
    query_image_path: str,
    feats_npy: str = FEATURES_NPY,
    paths_npy: str = PATHS_NPY,
    csv_path: str = PRODUCTS_INFO_CSV,
    base_dir: str = IMAGE_BASE_DIR,
    topk: int = TOPK,
    left: Optional[str] = None,
    rear: Optional[str] = None,
    right: Optional[str] = None,
    base_bias: float = 0.7,
) -> dict:
    """
    run_full_pipelineì„ ì‹¤í–‰í•˜ê³  ìµœì¢… JSON í˜•íƒœë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    out = run_full_pipeline(
        query_image_path=query_image_path,
        feats_npy=feats_npy,
        paths_npy=paths_npy,
        csv_path=csv_path,
        base_dir=base_dir,
        topk=topk,
        left=left, rear=rear, right=right,
    )

    # ---- ìµœì¢… JSON ìŠ¤í‚¤ë§ˆ êµ¬ì„± ----
    baseline_price = out.get("baseline_price")  # ì¤‘ê³  ê¸°ì¤€ê°€(used avg)
    retail_price   = out.get("retail_price")    # ì‹ ì œí’ˆê°€
    toy_name       = out.get("toy_name")

    # Fallback: predictê°€ toy_nameì„ ëª» ì¤€ ê²½ìš° (êµ¬í˜• CSV ëŒ€ë¹„)
    if not toy_name:
        ref_path_for_title = out.get("ref_image_path")
        toy_name = get_title_from_csv(out.get("csv_path"), ref_path_for_title)

    # ì—ì´ì „íŠ¸ ê²°ê³¼ (ë“±ê¸‰ ìš°ì„ )
    damage_grade = out.get("íŒŒì† ìƒëŒ€ë“±ê¸‰")                      # 'A'..'E'
    # Soil: ìš°ì„  ë“±ê¸‰, ì—†ìœ¼ë©´ -2..+2 â†’ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜, ê·¸ë˜ë„ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸
    soil_grade = out.get("ì˜¤ì—¼ ìƒëŒ€ë“±ê¸‰")
    if not soil_grade:
        lvl = out.get("ê¸°ì¤€ ëŒ€ë¹„(ì˜¤ì—¼)")
        if lvl is not None:
            try:
                soil_grade = _level_to_grade(int(lvl))
            except Exception:
                soil_grade = None

    # ë§¤ì…ê°€ ê³„ì‚° (baseline_priceê°€ ìˆì„ ë•Œë§Œ), íŒŒì†/ì˜¤ì—¼ ëª¨ë‘ ë“±ê¸‰ ê¸°ë°˜
    purchase_price = None
    if baseline_price is not None:
        rec = estimate_purchase_price_by_grade(
            baseline_price=int(baseline_price),
            damage_grade=damage_grade,
            soil_grade=soil_grade,
            base_bias=base_bias,
        )
        purchase_price = int(rec["recommended_price"])

    final_json = {
        "toy_name": toy_name,
        "retail_price": int(retail_price) if retail_price is not None else None,
        "purchase_price": purchase_price,
        "soil": soil_grade if soil_grade else out.get("ì˜¤ì—¼ë„"),
        "damage": damage_grade if damage_grade else out.get("íŒŒì†ë„"),
        "toy_type": out.get("ì¢…ë¥˜"),
        "material": out.get("ì†Œì¬"),
    }
    
    return final_json


if __name__ == "__main__":
    main()
